<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>performance</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="github-styles.css" />
</head>
<body>
<h1 id="performance-and-efficiency">Performance and Efficiency</h1>
<p>Performance and efficiency have multiple aspects: ease of learning
and usage (developer productivity), compilation speed, startup time,
runtime performance, and memory usage.</p>
<p>This language transpiles to C, which has a highly optimized
toolchain, and is available for embedded systems, desktops, and servers.
Startup time is significantly faster than that of virtual machine-based
languages like Java or C#, as there is no VM or runtime to initialize.
Runtime performance: this language aims to be in the same category as
high-performance languages such as C, Rust, Go, Java, and Swift. To
ensure low memory usage and to avoid GC pauses, it does not use tracing
garbage collection.</p>
<p>Memory safety results in runtime overhead from reference counting and
array bounds checking. However, for performance-critical sections, this
overhead can be mitigated: The language supports ownership semantics for
references, and range-restricted index variables, so that the compiler
can eliminate these checks where applicable. The complexity of these
features is however not needed in the majority of the cases, which
results in simple code and high productivity.</p>
<h2 id="benchmarks">Benchmarks</h2>
<img src="performance.png">

<table>
<thead>
<tr>
<th>Benchmark</th>
<th>Bau</th>
<th>C</th>
<th>Go</th>
<th>Java</th>
<th>Nim</th>
<th>PyPy</th>
<th>Rust</th>
<th>Swift</th>
<th>Vlang</th>
<th>Zig</th>
</tr>
</thead>
<tbody>
<tr>
<td>Binary Trees</td>
<td>5.1</td>
<td>5.1</td>
<td>11.0</td>
<td>3.4</td>
<td>5.2</td>
<td>8.5</td>
<td>5.9</td>
<td>12.0</td>
<td>7.5</td>
<td>6.6</td>
</tr>
<tr>
<td>Fannkuch</td>
<td>2.1</td>
<td>2.2</td>
<td>2.2</td>
<td>2.1</td>
<td>2.3</td>
<td>5.2</td>
<td>2.0</td>
<td>2.3</td>
<td>2.1</td>
<td>2.1</td>
</tr>
<tr>
<td>SpeedTest</td>
<td>1.8</td>
<td>1.8</td>
<td>3.2</td>
<td>4.4</td>
<td>2.5</td>
<td>15.4</td>
<td>1.8</td>
<td>1.9</td>
<td>1.8</td>
<td>1.6</td>
</tr>
<tr>
<td>Pi Digits</td>
<td>2.6</td>
<td>0.5</td>
<td>1.0</td>
<td>3.5</td>
<td>32.0</td>
<td>2.3</td>
<td>1.5</td>
<td>7.7</td>
<td>5.3</td>
<td>5.7</td>
</tr>
<tr>
<td>Mandelbrot</td>
<td>3.5</td>
<td>3.5</td>
<td>3.5</td>
<td>3.8</td>
<td>3.5</td>
<td>14.9</td>
<td>3.8</td>
<td>17.0</td>
<td>3.6</td>
<td>15.7</td>
</tr>
</tbody>
</table>
<p>(Runtime in seconds; lower is better. Measured on an Apple MacBook
Pro M1.) For Python, PyPy is used; CPython is around 50 times
slower.</p>
<h3 id="disclaimer">Disclaimer</h3>
<p>These benchmarks are not designed to show a language is "better" than
another language. Performance depends on many factors such as the
algorithm used, the developer, how much time is spend on optimizations,
etc. Also, measurements vary with hardware, compiler, or operating
system.</p>
<p>Why then publish these benchmarks? Performance is an important aspect
when selecting a programming language. It is true that benchmarks are
often used to mislead: cherry-picking, comparing old version of
competitors, not specifying the details (compiler flags etc.). However,
not doing any benchmarks is not a solution either. Computer science
papers, for example, are often required to include benchmarks. It is
expected that performance is measured. So it is a double-edged sword:
many like to see benchmarks results, but many will criticise the result
- no matter how the benchmarks are done or what the results show. In the
field of database engines, the "DeWitt Clause" is used, which prevents
people (competitors) from publishing benchmark results. These clauses
were included in licenses of databases because DeWitt, a researcher,
conducted benchmark studies showed performance issues in popular
databases. But for programming languages, very few (commercial)
languages use such licenses.</p>
<p>Only a small number of benchmarks are implemented so far, most of
them are based on the microbenchmarks from
<a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/index.html">The
Computer Language Benchmarks Game</a>.</p>
<p>For all languages, a very simple single-threaded implementation is
used (without inline assembly etc.). Memory usage is not currently
measured. The tests are run 3 times, and the best time is used.
Benchmark results in seconds (lower is better). For Java, memory is
limited to 100 MB by using <code>-Xmx100m</code>, and the just-in-time
compiler is pre-warmed by running the same test 3 times inside the same
JVM.</p>
<p>What this page tries to show is that, for these limited benchmarks,
Bau has a similar performance then other popular programming languages,
specially C. Which makes sense, because it is transpiled to C. It is
sometimes slower, and sometimes faster, than Java, Go, and Rust.</p>
<h3 id="languages">Languages</h3>
<ul>
<li>C: The default C compiler of the environment is used, which is Apple
clang version 16.0.0 currently.</li>
<li>Go: Version 1.24.4 darwin/arm64 is use.</li>
<li>Java: OpenJDK version 24.0.2 is used.</li>
<li>Nim: Version 2.2.4 is used.</li>
<li>Python: PyPy is used; CPython is around 50 times slower. The version
used is PyPy 7.3.19 with GCC Apple LLVM 16.0.0.</li>
<li>Rust: RustC version 1.75.0 is used.</li>
<li>Swift: Apple Swift version 6.0.3 is used.</li>
<li>Vlang: Version 0.4.11 is used. Notice that V used the
<a href="https://en.wikipedia.org/wiki/Boehm_garbage_collector">Boehm GC
library</a>.</li>
<li>Zig: Version 0.15.1. Note that Zig is not a memory-safe language,
similar to C.</li>
</ul>
<h3 id="benchmarks-1">Benchmarks</h3>
<h4 id="binary-trees">Binary Trees</h4>
<p>This test
<a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/description/binarytrees.html#binarytrees">generates
binary trees and counts the nodes</a>. The Java version is very fast if
given enough memory, because it doesn't collect garbage; when limiting
memory to 100 MB, it does collect garbage, but in a different thread.
The Go garbage collector is limited to one thread using
"runtime.GOMAXPROCS(1)", and so it is slower than Java, which can not be
limited to one thread (which is arguably not fair). For Bau, the
ownership variant is used; the reference counted variant is a bit
slower. Bau includes a faster malloc implementation, which would brings
performance close to Java. The command line argument 20 is used instead
of 21 as in the original test, to speed up running the test; however the
relative performance is unaffected.</p>
<h4 id="fannkuch">Fannkuch</h4>
<p>This test simulates
<a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/description/fannkuchredux.html#fannkuchredux">flipping
pancakes</a>. This test uses many array accesses. For Bau, no attempt
was made to eliminate bound checks. It unclear why the C version is a
little bit slower then the C version created from Bau. The command line
argument 11 is used instead of 12 as in the original test, to speed up
running the test; however the relative performance is unaffected.</p>
<h4 id="speedtest">SpeedTest</h4>
<p>This test is about the
<a href="https://github.com/jabbalaci/SpeedTests">MÃ¼nchausen numbers
problem</a>. This is a very fast loop with a lot of array access.
(Standard) Python is particularly slow here because it is interpreted
and doesn't use a JIT compiler. The same settings are used as in the
original benchmark.</p>
<h4 id="pi-digits">Pi Digits</h4>
<p>This uses a big integer library that computes
<a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/description/pidigits.html#pidigits">10'000
digits of Pi</a>. The same settings are used as in the original
benchmark.</p>
<p>Performance depends mostly on the big integer library. The big
integer library of Go, for example, is highly optimized, and using
platform-specific assembly. The Rust library is highly optimized as
well, but the C "gmp" library is the fastest. The Swift library
"attaswift/BigInt" is used. For Nim, nim-lang/bigints is used, where
multiplication and division are not optimized for performance. The Bau
bigint library is around 400 lines of code, modelled after the Java
library, without platform-specific code. Bau, as well as other
languages, could easily use the "gmp" library as well.</p>
<h4 id="mandelbrot">Mandelbrot</h4>
<p>This test computes the
<a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/description/mandelbrot.html#mandelbrot">Mandelbrot
set</a>. Only 8'000 by 8'000 pixels are calculated, versus 16'000 by
16'000 as in the original test, to speed up running the test; however
the relative performance is unaffected. It is mostly testing floating
point performance.</p>
<h2 id="building-and-running-the-tests">Building and Running the
Tests</h2>
<p>Download and build the latest version:</p>
<pre><code>git clone git@github.com:thomasmueller/bau-lang.git
cd bau-lang</code></pre>
<p>Using Maven:</p>
<pre><code>mvn -DskipTests clean install</code></pre>
<p>Using Make:</p>
<pre><code>make jar</code></pre>
<p>Compiling and Running the C, Java, and Bau versions:</p>
<pre><code>mkdir -p target
cd target

echo &quot;== Bau ============&quot;
cp ../src/test/resources/org/bau/benchmarks/bau/* .
find . -type f ! -name &quot;*.?*&quot; -delete
java -jar bau.jar -O3 -useTmMalloc false *.bau
for i in {1..3}; do time ./binaryTrees 20; done
for i in {1..3}; do time ./binaryTreesRefCount 20; done
for i in {1..3}; do time ./fannkuch 11; done
for i in {1..3}; do time ./munchausen; done
for i in {1..3}; do time ./piDigits &gt; out.txt; done
for i in {1..3}; do time ./mandelbrot 8000 &gt; out.tiff; done
java -jar bau.jar -useTmMalloc true -O3 *.bau
for i in {1..3}; do time ./binaryTrees 20; done
for i in {1..3}; do time ./binaryTreesRefCount 20; done

echo &quot;== C ============&quot;
cp ../src/test/resources/org/bau/benchmarks/c/* .
find . -type f ! -name &quot;*.?*&quot; -delete
gcc -O3 binaryTrees.c -o binaryTrees
gcc -O3 fannkuch.c -o fannkuch
gcc -O3 munchausen.c -o munchausen
gcc -O3 piDigits.c -o piDigits -I/opt/homebrew/include -L/opt/homebrew/lib -lgmp
gcc -O3 mandelbrot.c -o mandelbrot
for i in {1..3}; do time ./binaryTrees 20; done
for i in {1..3}; do time ./fannkuch 11; done
for i in {1..3}; do time ./munchausen; done
for i in {1..3}; do time ./piDigits 10000 &gt; out.txt; done
for i in {1..3}; do time ./mandelbrot 8000 &gt; out.tiff; done

echo &quot;== Go ============&quot;
cp ../src/test/resources/org/bau/benchmarks/go/* .
find . -type f ! -name &quot;*.?*&quot; -delete
go build -ldflags=&quot;-s -w&quot; binaryTrees.go
go build -ldflags=&quot;-s -w&quot; fannkuch.go
go build -ldflags=&quot;-s -w&quot; munchausen.go
go build -ldflags=&quot;-s -w&quot; piDigits.go
go build -ldflags=&quot;-s -w&quot; mandelbrot.go
for i in {1..3}; do time ./binaryTrees 20; done
for i in {1..3}; do time ./fannkuch 11; done
for i in {1..3}; do time ./munchausen; done
for i in {1..3}; do time ./piDigits &gt; out.txt; done
for i in {1..3}; do time ./mandelbrot 8000 &gt; out.tiff; done

echo &quot;== Java ============&quot;
javac ../src/test/java/org/bau/benchmarks/*.java -d .
time java -Xmx100m org.bau.benchmarks.Loop org.bau.benchmarks.BinaryTrees 20
time java -Xmx100m org.bau.benchmarks.Loop org.bau.benchmarks.Fannkuch 11
time java -Xmx100m org.bau.benchmarks.Loop org.bau.benchmarks.Munchausen
time java -Xmx100m org.bau.benchmarks.Loop org.bau.benchmarks.PiDigits 10000 | grep Run
time java -Xmx100m org.bau.benchmarks.Loop org.bau.benchmarks.Mandelbrot 8000 | grep -a Run
for i in {1..3}; do time java -Xmx100m org.bau.benchmarks.BinaryTrees 20; done
for i in {1..3}; do time java -Xmx100m org.bau.benchmarks.Fannkuch 11; done
for i in {1..3}; do time java -Xmx100m org.bau.benchmarks.Munchausen; done
for i in {1..3}; do time java -Xmx100m org.bau.benchmarks.PiDigits 10000 &gt; out.txt; done
for i in {1..3}; do time java -Xmx100m org.bau.benchmarks.Mandelbrot 8000 &gt; out.tiff; done

echo &quot;== Nim ============&quot;
cp ../src/test/resources/org/bau/benchmarks/nim/* .
find . -type f ! -name &quot;*.?*&quot; -delete
nim c -d:release binaryTrees.nim
nim c -d:release fannkuch.nim
nim c -d:release munchausen.nim
nim c -d:release piDigits.nim
nim c -d:release mandelbrot.nim
for i in {1..3}; do time ./binaryTrees 20; done
for i in {1..3}; do time ./fannkuch 11; done
for i in {1..3}; do time ./munchausen; done
for i in {1..3}; do time ./piDigits 10000 &gt; out.txt; done
for i in {1..3}; do time ./mandelbrot 8000 &gt; out.tiff; done

echo &quot;== Python via PyPy ============&quot;
cp ../src/test/resources/org/bau/benchmarks/python/* .
for i in {1..3}; do time pypy3.10 binaryTrees.py 20; done
for i in {1..3}; do time pypy3.10 fannkuch.py 11; done
for i in {1..3}; do time pypy3.10 munchausen.py; done
for i in {1..3}; do time pypy3.10 piDigits.py 10000 &gt; out.txt; done
for i in {1..3}; do time pypy3.10 mandelbrot.py 8000 &gt; out.tiff; done

echo &quot;== Rust ============&quot;
cp ../src/test/resources/org/bau/benchmarks/rust/*.rs .
find . -type f ! -name &quot;*.?*&quot; -delete
rm -rf rust
mkdir -p rust
cp -R ../src/test/resources/org/bau/benchmarks/rust .
cd rust
cargo build --release
cd ..
rustc -C opt-level=3 binaryTrees.rs
rustc -C opt-level=3 fannkuch.rs
rustc -C opt-level=3 munchausen.rs
rustc -C opt-level=3 mandelbrot.rs
for i in {1..3}; do time ./binaryTrees 20; done
for i in {1..3}; do time ./fannkuch 11; done
for i in {1..3}; do time ./munchausen; done
for i in {1..3}; do time ./rust/target/release/pi_digits &gt; out.txt; done
for i in {1..3}; do time ./mandelbrot 8000 &gt; out.tiff; done

echo &quot;== Swift ============&quot;
cp ../src/test/resources/org/bau/benchmarks/swift/*.swift .
find . -type f ! -name &quot;*.?*&quot; -delete
mkdir -p swift
cp -R ../src/test/resources/org/bau/benchmarks/swift .
cd swift/piDigits
swift build -c release
cp .build/arm64-apple-macosx/release/piDigits ../..
cd ../..
swiftc -O binaryTrees.swift -o binaryTrees
swiftc -O fannkuch.swift -o fannkuch
swiftc -O munchausen.swift -o munchausen
swiftc -O mandelbrot.swift -o mandelbrot
for i in {1..3}; do time ./binaryTrees 20; done
for i in {1..3}; do time ./fannkuch 11; done
for i in {1..3}; do time ./munchausen; done
for i in {1..3}; do time ./piDigits 10000 &gt; out.txt; done
for i in {1..3}; do time ./mandelbrot 8000 &gt; out.tiff; done

echo &quot;== Vlang ============&quot;
cp ../src/test/resources/org/bau/benchmarks/v/* .
find . -type f ! -name &quot;*.?*&quot; -delete
./v -prod -force-bounds-checking binaryTrees.v
./v -prod -force-bounds-checking fannkuch.v
./v -prod -force-bounds-checking munchausen.v
./v -prod -force-bounds-checking -enable-globals piDigits.v
./v -prod -force-bounds-checking mandelbrot.v
for i in {1..3}; do time ./binaryTrees 20; done
for i in {1..3}; do time ./fannkuch 11; done
for i in {1..3}; do time ./munchausen; done
for i in {1..3}; do time ./piDigits &gt; out.txt; done
for i in {1..3}; do time ./mandelbrot 8000 &gt; out.tiff; done

echo &quot;== Zig ============&quot;
cp ../src/test/resources/org/bau/benchmarks/zig/* .
find . -type f ! -name &quot;*.?*&quot; -delete
zig build-exe -O ReleaseSafe binaryTrees.zig
zig build-exe -O ReleaseSafe fannkuch.zig
zig build-exe -O ReleaseSafe munchausen.zig
zig build-exe -O ReleaseSafe piDigits.zig
zig build-exe -O ReleaseSafe mandelbrot.zig
for i in {1..3}; do time ./binaryTrees 20; done
for i in {1..3}; do time ./fannkuch 11; done
for i in {1..3}; do time ./munchausen; done
for i in {1..3}; do time ./piDigits &gt; out.txt; done
for i in {1..3}; do time ./mandelbrot 8000 &gt; out.tiff; done

echo &quot;== Python (CPython) ============&quot;
cp ../src/test/resources/org/bau/benchmarks/python/* .
for i in {1..3}; do time python binaryTrees.py 20; done
for i in {1..3}; do time python fannkuch.py 11; done
for i in {1..3}; do time python piDigits.py 10000 &gt; out.txt; done
for i in {1..3}; do time python munchausen.py; done
for i in {1..3}; do time python mandelbrot.py 8000 &gt; out.tiff; done

cd ..</code></pre>
</body>
</html>
